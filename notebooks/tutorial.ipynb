{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process calcium imaging data with DataJoint Elements\n",
    "\n",
    "This notebook will walk through processing two-photon calcium imaging data collected\n",
    "from ScanImage, Scanbox, Nikon NIS, or PrairieView. Later, you'll pict from either\n",
    "Suite2p or CaImAn for analysis.\n",
    "\n",
    "The DataJoint Python API and Element Calcium Imaging offer a lot of features to support collaboration, automation, reproducibility, and visualization. For more information on these topics, please visit our documentation: \n",
    " \n",
    "- [DataJoint Core](https://datajoint.com/docs/core/): General principles\n",
    "\n",
    "- DataJoint [Python](https://datajoint.com/docs/core/datajoint-python/) and\n",
    "  [MATLAB](https://datajoint.com/docs/core/datajoint-matlab/) APIs: in-depth reviews of\n",
    "  specifics\n",
    "\n",
    "- [Element Calcium Imaging](https://datajoint.com/docs/elements/element-calcium-imaging/):\n",
    "  A modular pipeline for 2p data analysis\n",
    "\n",
    "## Setup - Working Directory\n",
    "\n",
    "To run the workflow, we need to properly set up the DataJoint configuration. The configuration can be saved in a local directory as `dj_local_conf.json` or at your root directory as a hidden file. This notebook walks you through the setup process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Credentials\n",
    "\n",
    "Now let's set up the host, user and password in the `dj.config` global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - `dj.config['custom']`\n",
    "\n",
    "The major component of the current workflow is the [DataJoint Calcium Imaging Element](https://github.com/datajoint/element-array-ephys). Calcium Imaging Element requires configurations in the field `custom` in `dj.config`:\n",
    "\n",
    "### Database prefix\n",
    "\n",
    "Giving a prefix to schema could help on the configuration of privilege settings. For example, if we set prefix `neuro_`, every schema created with the current workflow will start with `neuro_`, e.g. `neuro_lab`, `neuro_subject`, `neuro_scan` etc.\n",
    "\n",
    "The prefix could be configured in `dj.config` as follows. CodeBook users should keep their username as the prefix for schema declaration permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username_as_prefix = dj.config[\"database.user\"] + \"_\"\n",
    "dj.config[\"custom\"] = {\"database.prefix\": username_as_prefix}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root directories for raw/processed data\n",
    "\n",
    "`imaging_root_data_dir` field indicates the root directory for\n",
    "+ The **raw data** from ScanImage or Scanbox (e.g. `*.tif`)\n",
    "+ The processed results from Suite2p or CaImAn (e.g. `F.npy`). \n",
    "\n",
    "This can be specific to each machine. The root path typically **does not** contain information of subjects or sessions, all data from subjects/sessions should be subdirectories in the root path.\n",
    "\n",
    "+ In the example dataset downloaded with [these instructions](00-data-download-optional.ipynb), `/tmp/test_data` will be the root. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example dataset is attached to this GitHub Codespace environment, so the root directory will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config[\"custom\"][\"imaging_root_data_dir\"] = \"/tmp/example_data\"  # local download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save configuration\n",
    "\n",
    "We could save this as a file, either as a local json file, or a global file. Local configuration file is saved as `dj_local_conf.json` in current directory, which is great for project-specific settings.\n",
    "\n",
    "For first-time and CodeBook users, we recommend saving globally. This will create a hidden configuration file saved in your root directory, loaded whenever there is no local version to override it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config.save_local()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate DataJoint Elements\n",
    "\n",
    "+ The current workflow is composed of multiple database schemas, each of them corresponds to a module within `workflow_calcium_imaging.pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow_calcium_imaging.pipeline import lab, subject, session, scan, imaging, Equipment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow diagram\n",
    "\n",
    "This workflow is assembled from 4 DataJoint elements:\n",
    "+ [element-lab](https://github.com/datajoint/element-lab)\n",
    "+ [element-animal](https://github.com/datajoint/element-animal)\n",
    "+ [element-session](https://github.com/datajoint/element-session)\n",
    "+ [element-calcium-imaging](https://github.com/datajoint/element-calcium-imaging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dj.Diagram(subject.Subject)\n",
    "    + dj.Diagram(session.Session)\n",
    "    + dj.Diagram(scan)\n",
    "    + dj.Diagram(imaging)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject.insert1(\n",
    "    dict(\n",
    "        subject=\"subject1\",\n",
    "        sex=\"F\",\n",
    "        subject_birth_date=\"2020-01-01\",\n",
    "        subject_description=\"ScanImage acquisition. Suite2p processing.\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Equipment.insert1(dict(scanner=\"ScanImage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_key = dict(subject=\"subject1\", session_datetime=\"2021-04-30 12:22:15.032\")\n",
    "\n",
    "session.Session.insert1(session_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.SessionDirectory.insert1(\n",
    "    dict(**session_key,\n",
    "        session_dir=\"subject1/session1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.Scan.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        scan_id=0,\n",
    "        scanner=\"ScanImage\",\n",
    "        acq_software=\"ScanImage\",\n",
    "        scan_notes=\"\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_settings = {\n",
    "                    \"display_progress\": True,\n",
    "                    \"reserve_jobs\": False,\n",
    "                    \"suppress_errors\": False,\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.ScanInfo.populate(**populate_settings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Suite2p parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_suite2p = {\n",
    "    \"look_one_level_down\": 0.0,\n",
    "    \"fast_disk\": [],\n",
    "    \"delete_bin\": False,\n",
    "    \"mesoscan\": False,\n",
    "    \"h5py\": [],\n",
    "    \"h5py_key\": \"data\",\n",
    "    \"save_path0\": [],\n",
    "    \"subfolders\": [],\n",
    "    \"nplanes\": 1,\n",
    "    \"nchannels\": 1,\n",
    "    \"functional_chan\": 1,\n",
    "    \"tau\": 1.0,\n",
    "    \"fs\": 10.0,\n",
    "    \"force_sktiff\": False,\n",
    "    \"preclassify\": 0.0,\n",
    "    \"save_mat\": False,\n",
    "    \"combined\": True,\n",
    "    \"aspect\": 1.0,\n",
    "    \"do_bidiphase\": False,\n",
    "    \"bidiphase\": 0.0,\n",
    "    \"do_registration\": True,\n",
    "    \"keep_movie_raw\": False,\n",
    "    \"nimg_init\": 300,\n",
    "    \"batch_size\": 500,\n",
    "    \"maxregshift\": 0.1,\n",
    "    \"align_by_chan\": 1,\n",
    "    \"reg_tif\": False,\n",
    "    \"reg_tif_chan2\": False,\n",
    "    \"subpixel\": 10,\n",
    "    \"smooth_sigma\": 1.15,\n",
    "    \"th_badframes\": 1.0,\n",
    "    \"pad_fft\": False,\n",
    "    \"nonrigid\": True,\n",
    "    \"block_size\": [128, 128],\n",
    "    \"snr_thresh\": 1.2,\n",
    "    \"maxregshiftNR\": 5.0,\n",
    "    \"1Preg\": False,\n",
    "    \"spatial_hp\": 50.0,\n",
    "    \"pre_smooth\": 2.0,\n",
    "    \"spatial_taper\": 50.0,\n",
    "    \"roidetect\": True,\n",
    "    \"sparse_mode\": False,\n",
    "    \"diameter\": 12,\n",
    "    \"spatial_scale\": 0,\n",
    "    \"connected\": True,\n",
    "    \"nbinned\": 5000,\n",
    "    \"max_iterations\": 20,\n",
    "    \"threshold_scaling\": 1.0,\n",
    "    \"max_overlap\": 0.75,\n",
    "    \"high_pass\": 100.0,\n",
    "    \"inner_neuropil_radius\": 2,\n",
    "    \"min_neuropil_pixels\": 350,\n",
    "    \"allow_overlap\": False,\n",
    "    \"chan2_thres\": 0.65,\n",
    "    \"baseline\": \"maximin\",\n",
    "    \"win_baseline\": 60.0,\n",
    "    \"sig_baseline\": 10.0,\n",
    "    \"prctile_baseline\": 8.0,\n",
    "    \"neucoeff\": 0.7,\n",
    "    \"xrange\": np.array([0, 0]),\n",
    "    \"yrange\": np.array([0, 0]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingParamSet.insert_new_params(\n",
    "    processing_method=\"suite2p\",\n",
    "    paramset_idx=0,\n",
    "    params=params_suite2p,\n",
    "    paramset_desc=\"Calcium imaging analysis with Suite2p using default Suite2p parameters\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingTask.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        scan_id=0,\n",
    "        paramset_idx=0,\n",
    "        processing_output_dir=\"subject1/session1/suite2p\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Processing.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Curation.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        scan_id=0,\n",
    "        paramset_idx=0,\n",
    "        curation_id=0,\n",
    "        curation_time=\"2021-04-30 12:22:15.032\",\n",
    "        curation_output_dir=\"subject1/session1/suite2p\",\n",
    "        manual_curation=False,\n",
    "        curation_note=\"\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MotionCorrection.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Segmentation.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Fluorescence.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Activity.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query and fetch data\n",
    "\n",
    "+ DataJoint provides functions to query data and fetch.  For a detailed tutorials, visit our [general tutorial site](https://playground.datajoint.io/).\n",
    "\n",
    "+ Running through the pipeline, we have ingested data of subject3 into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_key = (session.Session & 'subject = \"subject1\"').fetch(\"KEY\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `imaging.ProcessingParamSet`, `imaging.ProcessingTask`, `imaging.Processing`, and `imaging.Curation` tables\n",
    "\n",
    "+ The parameters used for Suite2p or CaImAn are stored in `imaging.ProcessingParamSet` under a `paramset_idx`.\n",
    "\n",
    "+ The processing details for Suite2p and CaImAn are stored in `imaging.ProcessingTask` and `imaging.Processing` for the utilized `paramset_idx`.\n",
    "\n",
    "+ After the motion correction and segmentation, the results may go through a curation process. \n",
    "    \n",
    "    + If it did not go through curation, a copy of the `imaging.ProcessingTask` entry is inserted into `imaging.Curation` with the `curation_output_dir` identical to the `processing_output_dir`.\n",
    "\n",
    "    + If it did go through a curation, a new entry will be inserted into `imaging.Curation`, with a `curation_output_dir` specified.\n",
    "\n",
    "    + `imaging.Curation` supports multiple curations of an entry in `imaging.ProcessingTask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingParamSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingTask * imaging.Processing & session_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example workflow, `curation_output_dir` is the same as the `processing_output_dir`, as these results were not manually curated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Curation & session_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `imaging.MotionCorrection` table\n",
    "\n",
    "+ After processing and curation, results are passed to the `imaging.MotionCorrection` and `imaging.Segmentation` tables.\n",
    "\n",
    "+ For the example data, the raw data is corrected with rigid and non-rigid motion correction which is stored in `imaging.MotionCorrection.RigidMotionCorrection` and `imaging.MotionCorrection.NonRigidMotionCorrection`, respectively. \n",
    "\n",
    "+ Lets first query the information for one curation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_key = (imaging.Curation & session_key & \"curation_id=0\").fetch1(\"KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MotionCorrection.RigidMotionCorrection & curation_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MotionCorrection.NonRigidMotionCorrection & curation_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ For non-rigid motion correction, the details for the individual blocks are stored in `imaging.MotionCorrection.Block`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MotionCorrection.Block & curation_key & \"block_id=0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Summary images are stored in `imaging.MotionCorrection.Summary`\n",
    "\n",
    "    + Reference image - image used as an alignment template\n",
    "\n",
    "    + Average image - mean of registered frames\n",
    "\n",
    "    + Correlation image - correlation map (computed during region of interest \\[ROI\\] detection)\n",
    "\n",
    "    + Maximum projection image - max of registered frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MotionCorrection.Summary & curation_key & \"field_idx=0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Lets fetch the `average_image` and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_image = (\n",
    "    imaging.MotionCorrection.Summary & curation_key & \"field_idx=0\"\n",
    ").fetch1(\"average_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(average_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `imaging.Segmentation` table\n",
    "\n",
    "+ Lets fetch and plot a mask stored in the `imaging.Segmentation.Mask` table for one `curation_id`.\n",
    "\n",
    "+ Each mask can be associated with a field by the attribute `mask_center_z`.  For example, masks with `mask_center_z=0` are in the field identified with `field_idx=0` in `scan.ScanInfo.Field`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_xpix, mask_ypix = (\n",
    "    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n",
    "    & curation_key\n",
    "    & \"mask_center_z=0\"\n",
    "    & \"mask_npix > 130\"\n",
    ").fetch(\"mask_xpix\", \"mask_ypix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image = np.zeros(np.shape(average_image), dtype=bool)\n",
    "for xpix, ypix in zip(mask_xpix, mask_ypix):\n",
    "    mask_image[ypix, xpix] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(average_image)\n",
    "plt.contour(mask_image, colors=\"white\", linewidths=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `imaging.MaskClassification` table\n",
    "\n",
    "+ This table provides the `mask_type` and `confidence` for the mask classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MaskClassification.MaskType & curation_key & \"mask=0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `imaging.Fluorescence` and `imaging.Activity` tables\n",
    "\n",
    "+ Lets fetch and plot the flourescence and activity traces for one mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cells = (\n",
    "    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n",
    "    & curation_key\n",
    "    & \"mask_center_z=0\"\n",
    "    & \"mask_npix > 130\"\n",
    ").proj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluorescence_traces = (imaging.Fluorescence.Trace & query_cells).fetch(\n",
    "    \"fluorescence\", order_by=\"mask\"\n",
    ")\n",
    "\n",
    "activity_traces = (imaging.Activity.Trace & query_cells).fetch(\n",
    "    \"activity_trace\", order_by=\"mask\"\n",
    ")\n",
    "\n",
    "sampling_rate = (scan.ScanInfo & curation_key).fetch1(\"fps\")  # [Hz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 4))\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for f, a in zip(fluorescence_traces, activity_traces):\n",
    "    ax.plot(np.r_[: f.size] * 1 / sampling_rate, f, \"k\", label=\"fluorescence trace\")\n",
    "    ax2.plot(\n",
    "        np.r_[: a.size] * 1 / sampling_rate,\n",
    "        a,\n",
    "        \"r\",\n",
    "        alpha=0.5,\n",
    "        label=\"deconvolved trace\",\n",
    "    )\n",
    "\n",
    "    break\n",
    "\n",
    "ax.tick_params(labelsize=14)\n",
    "ax2.tick_params(labelsize=14)\n",
    "\n",
    "ax.legend(loc=\"upper left\", prop={\"size\": 14})\n",
    "ax2.legend(loc=\"upper right\", prop={\"size\": 14})\n",
    "\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Activity (a.u.)\")\n",
    "ax2.set_ylabel(\"Activity (a.u.)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop schemas\n",
    "\n",
    "+ Schemas are not typically dropped in a production workflow with real data in it. \n",
    "+ At the developmental phase, it might be required for the table redesign.\n",
    "+ When dropping all schemas is needed, the following is the dependency order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow_calcium_imaging.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imaging.schema.drop()\n",
    "# scan.schema.drop()\n",
    "# session.schema.drop()\n",
    "# subject.schema.drop()\n",
    "# lab.schema.drop()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "python3p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "ff52d424e56dd643d8b2ec122f40a2e279e94970100b4e6430cb9025a65ba4cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
